#!/usr/bin/env bash
# μµμ ν™”λ ν•κµ­μ–΄ GPT μ¬κ° μ¤ν¬λ¦½νΈ (Phase 1/Phase 2 μ „λµ)
#
# 2λ‹¨κ³„ ν•™μµ μ „λµ:
# Phase 1 (0β†’240k): GRAD_ACC=1, LR=2e-5 (λΉ λ¥Έ μλ ΄)
# Phase 2 (240kβ†’λ): GRAD_ACC=8, LR=5e-6 (μ•μ •ν™”)
#
# μ΄ μ¤ν¬λ¦½νΈλ” checkpoint stepμ— λ”°λΌ μλ™μΌλ΅ Phase μ„ νƒ:
# - Step < 240k: Phase 1 μ„¤μ • μ‚¬μ©
# - Step >= 240k: Phase 2 μ„¤μ • μ‚¬μ©
#
# Phase 1: λΉ λ¥Έ μλ ΄
# - LR: 2e-5 (κ³µκ²©μ )
# - GRAD_ACC: 1 (λΉ λ¥Έ ν•™μµ)
# - MAX_STEPS: 240000
#
# Phase 2: μ•μ •ν™”
# - LR: 5e-6 (μ•μ •μ )
# - GRAD_ACC: 8 (batch ν¬κΈ° μ¦κ°€)
# - EPOCHS: 3

set -euo pipefail

echo "================================================================"
echo "π”„ μµμ ν™”λ ν•κµ­μ–΄ GPT μ¬κ° - Transformer λ…Όλ¬Έ κΈ°λ°"
echo "================================================================"
echo ""

# ν™κ²½ ν™•μΈ
if [[ -z "${VIRTUAL_ENV:-}" ]]; then
  echo "[ERROR] κ°€μƒν™κ²½μ΄ ν™μ„±ν™”λμ§€ μ•μ•μµλ‹λ‹¤." >&2
  echo "μ‹¤ν–‰: source /mnt/sdc1/ws/workspace/.venv_indextts/bin/activate" >&2
  exit 1
fi

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
CHECKPOINT_DIR="${CHECKPOINT_DIR:-/mnt/sda1/models/index-tts-ko/checkpoints}"
RESUME_PATH="${RESUME_PATH:-${CHECKPOINT_DIR}/latest.pth}"
DATASET_DIR="${DATASET_DIR:-/mnt/sda1/emilia-yodas/KO_preprocessed}"
RAW_MANIFEST="${RAW_MANIFEST:-/mnt/sda1/emilia-yodas/KO/ko_manifest_raw.jsonl}"

SKIP_DATA_CHECK="${SKIP_DATA_CHECK:-1}"

# μ²΄ν¬ν¬μΈνΈ κ²€μ¦
if [[ ! -f "${RESUME_PATH}" ]]; then
  echo "[ERROR] μ²΄ν¬ν¬μΈνΈλ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤: ${RESUME_PATH}" >&2
  exit 1
fi

CKPT_SIZE=$(stat -c%s "${RESUME_PATH}" 2>/dev/null || stat -f%z "${RESUME_PATH}" 2>/dev/null)
CKPT_SIZE_GB=$((CKPT_SIZE / 1024 / 1024 / 1024))

echo "π“ μ²΄ν¬ν¬μΈνΈ μ •λ³΄:"
echo "  - κ²½λ΅: ${RESUME_PATH}"
echo "  - ν¬κΈ°: ${CKPT_SIZE_GB}GB"
echo "  - μμ •: $(ls -lh "${RESUME_PATH}" | awk '{print $6, $7, $8}')"
echo ""

# GPU ν™•μΈ
GPU_MEM=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
GPU_NAME=$(nvidia-smi --query-gpu=name --format=csv,noheader | head -1)

echo "β… GPU: ${GPU_NAME}"
echo "β… VRAM: ${GPU_MEM}MB"
echo ""

# λ°μ΄ν„° λ¬΄κ²°μ„± μ²΄ν¬ (μµμ…)
if [[ "${SKIP_DATA_CHECK}" != "1" ]]; then
  echo "π” λ°μ΄ν„° λ¬΄κ²°μ„± κ²€μ‚¬ μ¤‘..." >&2
  DATASET_DIR="${DATASET_DIR}" RAW_MANIFEST="${RAW_MANIFEST}" \
    "${SCRIPT_DIR}/ko_step2_fix_broken.sh" --scan-empty --scan-missing
else
  echo "β­οΈ  λ°μ΄ν„° κ²€μ‚¬ μƒλµ (SKIP_DATA_CHECK=1)" >&2
fi

# NUM_WORKERS μλ™ μ„¤μ • (μµλ€ μ„±λ¥ - CPU μ½”μ–΄ μ μ‚¬μ©)
if [[ -z "${NUM_WORKERS:-}" ]]; then
  CPU_CORES=$(nproc)
  export NUM_WORKERS=${CPU_CORES}
  echo "β™οΈ  NUM_WORKERS μλ™ μ„¤μ •: ${NUM_WORKERS} (CPU μ½”μ–΄ μ)" >&2
else
  echo "β™οΈ  NUM_WORKERS μ‚¬μ©μ μ„¤μ •: ${NUM_WORKERS}" >&2
fi

# μ²΄ν¬ν¬μΈνΈμ—μ„ step μ¶”μ¶
CKPT_STEP=0
if [[ "${RESUME_PATH}" =~ model_step([0-9]+)\.pth ]]; then
  CKPT_STEP="${BASH_MATCH[1]}"
elif python3 -c "import torch; print(torch.load('${RESUME_PATH}', map_location='cpu').get('step', 0))" 2>/dev/null | grep -q '^[0-9]\+$'; then
  CKPT_STEP=$(python3 -c "import torch; print(torch.load('${RESUME_PATH}', map_location='cpu').get('step', 0))")
fi

echo "π“ μ²΄ν¬ν¬μΈνΈ Step: ${CKPT_STEP}"
echo ""

# Phase μλ™ μ„ νƒ
PHASE_THRESHOLD=240000
if [[ ${CKPT_STEP} -lt ${PHASE_THRESHOLD} ]]; then
  PHASE="Phase 1"
  LR_VAL=2e-5
  GRAD_ACC_VAL=1
  GRAD_CLIP_VAL=1.0
  WARMUP_VAL=1000
  MAX_STEPS_VAL=240000
  EPOCHS_VAL=999
  echo "π€ Phase 1: λΉ λ¥Έ μλ ΄ (Step 0 β†’ 240k)"
  echo "  - LR: ${LR_VAL} (κ³µκ²©μ )"
  echo "  - GRAD_ACC: ${GRAD_ACC_VAL} (λΉ λ¥Έ ν•™μµ)"
  echo "  - GRAD_CLIP: ${GRAD_CLIP_VAL} (LRμ— λ§μ¶ μ•μ „μ¥μΉ)"
  echo "  - Warmup: ${WARMUP_VAL}"
  echo "  - Max Steps: ${MAX_STEPS_VAL}"
else
  PHASE="Phase 2"
  LR_VAL=5e-6
  GRAD_ACC_VAL=8
  GRAD_CLIP_VAL=0.5
  WARMUP_VAL=1000
  MAX_STEPS_VAL=0
  EPOCHS_VAL=3
  echo "π― Phase 2: μ•μ •ν™” (Step 240k β†’ λ)"
  echo "  - LR: ${LR_VAL} (μ•μ •μ )"
  echo "  - GRAD_ACC: ${GRAD_ACC_VAL} (batch ν¬κΈ° μ¦κ°€)"
  echo "  - GRAD_CLIP: ${GRAD_CLIP_VAL} (λ³΄μμ  μ•μ „μ¥μΉ)"
  echo "  - Warmup: ${WARMUP_VAL}"
  echo "  - Epochs: ${EPOCHS_VAL}"
fi

echo ""
echo "β™οΈ  κ³µν†µ μ„¤μ •:"
echo "  - Batch Size: 8 (RTX 4090 κ²€μ¦λ¨)"
echo ""

# μ‚¬μ©μ ν™•μΈ μ¤ν‚µ (μλ™ μ‹¤ν–‰)
echo "μλ™μΌλ΅ ${PHASE} ν•™μµμ„ μ¬κ°ν•©λ‹λ‹¤..."

echo ""
echo "π¬ ν•™μµμ„ μ¬κ°ν•©λ‹λ‹¤..."
echo "π“ TensorBoard: http://localhost:6006"
echo "π“ μ²΄ν¬ν¬μΈνΈ: ${CHECKPOINT_DIR}/"
echo ""

# Phaseλ³„ μµμ ν™” μ„¤μ •μΌλ΅ μ¬κ°
SKIP_DATA_CHECK=1 \
LR=${LR_VAL} \
WARMUP_STEPS=${WARMUP_VAL} \
BATCH_SIZE=8 \
GRAD_ACC=${GRAD_ACC_VAL} \
GRAD_CLIP=${GRAD_CLIP_VAL} \
LOG_INTERVAL=100 \
VAL_INTERVAL=10000 \
MAX_STEPS=${MAX_STEPS_VAL} \
EPOCHS=${EPOCHS_VAL} \
BASE_CHECKPOINT="/mnt/sda1/models/IndexTTS-2/gpt.pth" \
RESUME="${RESUME_PATH}" \
"${SCRIPT_DIR}/ko_step4_train_gpt.sh" "$@"

echo ""
echo "================================================================"
echo "β… ν•™μµ μ¬κ° μ™„λ£!"
echo "================================================================"
echo ""
echo "π“ μ €μ¥λ μ²΄ν¬ν¬μΈνΈ:"
echo "  - μµκ³  μ„±λ¥: ${CHECKPOINT_DIR}/best_model.pth"
echo "  - μµμ‹ : ${CHECKPOINT_DIR}/latest.pth"
echo ""
if [[ -f "${CHECKPOINT_DIR}/best_loss.txt" ]]; then
  echo "π― Best text_loss: $(cat "${CHECKPOINT_DIR}/best_loss.txt")"
fi
echo ""
echo "λ‹¤μ λ‹¨κ³„:"
echo "  1. TensorBoardλ΅ ν•™μµ κ³΅μ„  ν™•μΈ"
echo "  2. ${PHASE} μ™„λ£ ν›„ λ‹¤μ Phase μ§„ν–‰ (ν•΄λ‹Ήμ‹)"
echo "  3. best_model.pthλ΅ μμ„± μƒμ„± ν…μ¤νΈ"
echo ""
