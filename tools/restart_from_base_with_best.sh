#!/usr/bin/env bash
# Base ëª¨ë¸ë¶€í„° ìž¬í•™ìŠµ (Best Checkpoint ì €ìž¥ ê¸°ëŠ¥ ì¶”ê°€)

set -euo pipefail

echo "================================================================"
echo "Base ëª¨ë¸ë¶€í„° ìž¬í•™ìŠµ (Best Checkpoint ë³´ì¡´)"
echo "================================================================"
echo ""
echo "ê°œì„  ì‚¬í•­:"
echo "  âœ… Best checkpoint ìžë™ ì €ìž¥"
echo "  âœ… ìµœê·¼ 5ê°œ ì²´í¬í¬ì¸íŠ¸ ìœ ì§€ (ê¸°ì¡´ 3ê°œ â†’ 5ê°œ)"
echo "  âœ… Validation loss ê¸°ë¡ (VAL_INTERVAL=1000)"
echo ""
echo "================================================================"

# í™˜ê²½ í™•ì¸
if [[ -z "${VIRTUAL_ENV:-}" ]]; then
  echo "[ERROR] ê°€ìƒí™˜ê²½ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤." >&2
  echo "ì‹¤í–‰: source /mnt/sdc1/ws/workspace/.venv_indextts/bin/activate" >&2
  exit 1
fi

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
BASE_CHECKPOINT="/mnt/sda1/models/IndexTTS-2/gpt.pth"
BACKUP_DIR="/mnt/sda1/models/index-tts-ko/checkpoints_backup_$(date +%Y%m%d_%H%M%S)"

if [[ ! -f "${BASE_CHECKPOINT}" ]]; then
  echo "[ERROR] Base ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${BASE_CHECKPOINT}" >&2
  exit 1
fi

# ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ ë°±ì—… í™•ì¸
echo "âš ï¸  ê²½ê³ : ê¸°ì¡´ í•™ìŠµ ë°ì´í„°ë¥¼ ë°±ì—…í•©ë‹ˆë‹¤."
echo "ë°±ì—… ìœ„ì¹˜: ${BACKUP_DIR}"
echo ""
read -p "ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
  echo "ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤."
  exit 0
fi

# ë°±ì—…
echo "ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ ë°±ì—… ì¤‘..."
mkdir -p "${BACKUP_DIR}"
cp -r /mnt/sda1/models/index-tts-ko/checkpoints/* "${BACKUP_DIR}/" || true
echo "ë°±ì—… ì™„ë£Œ: ${BACKUP_DIR}"
echo ""

# Best checkpoint ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
cat > /tmp/monitor_best_checkpoint.py << 'EOF'
#!/usr/bin/env python3
"""
Best checkpoint ëª¨ë‹ˆí„°ë§ ë° ìžë™ ì €ìž¥
TensorBoard ë¡œê·¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì²´í¬í•˜ì—¬ ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë³„ë„ ì €ìž¥
"""
import time
import shutil
from pathlib import Path
from tensorboard.backend.event_processing import event_accumulator

log_dir = Path("/mnt/sda1/models/index-tts-ko/checkpoints/logs")
ckpt_dir = Path("/mnt/sda1/models/index-tts-ko/checkpoints")
best_ckpt_path = ckpt_dir / "best_model.pth"
best_loss_file = ckpt_dir / "best_loss.txt"

# ì´ˆê¸° best loss
if best_loss_file.exists():
    with open(best_loss_file, 'r') as f:
        best_loss = float(f.read().strip())
else:
    best_loss = float('inf')

print(f"Best checkpoint monitor started (current best: {best_loss:.4f})")

def get_latest_run():
    runs = sorted(log_dir.glob("run_*"))
    return runs[-1] if runs else None

last_checked_step = -1

while True:
    try:
        latest_run = get_latest_run()
        if not latest_run:
            time.sleep(30)
            continue

        ea = event_accumulator.EventAccumulator(str(latest_run))
        ea.Reload()

        # Validation loss í™•ì¸ (ì—†ìœ¼ë©´ train loss ì‚¬ìš©)
        loss_tag = 'val/mel_loss' if 'val/mel_loss' in ea.Tags()['scalars'] else 'train/mel_loss'

        if loss_tag not in ea.Tags()['scalars']:
            time.sleep(30)
            continue

        events = ea.Scalars(loss_tag)
        if not events:
            time.sleep(30)
            continue

        latest_event = events[-1]

        if latest_event.step == last_checked_step:
            time.sleep(30)
            continue

        last_checked_step = latest_event.step
        current_loss = latest_event.value

        # Best ì—…ë°ì´íŠ¸ í™•ì¸
        if current_loss < best_loss:
            best_loss = current_loss

            # í•´ë‹¹ stepì˜ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
            step_ckpt = ckpt_dir / f"model_step{latest_event.step}.pth"

            # 1000 step ë‹¨ìœ„ë¡œ ì €ìž¥ë˜ë¯€ë¡œ, ê°€ìž¥ ê°€ê¹Œìš´ step ì°¾ê¸°
            rounded_step = (latest_event.step // 1000) * 1000
            step_ckpt = ckpt_dir / f"model_step{rounded_step}.pth"

            if step_ckpt.exists():
                # Best checkpoint ë³µì‚¬
                shutil.copy2(step_ckpt, best_ckpt_path)

                # Best loss ì €ìž¥
                with open(best_loss_file, 'w') as f:
                    f.write(f"{best_loss:.6f}")

                print(f"\nðŸŽ‰ New best! Step {latest_event.step}: {current_loss:.4f} (saved to best_model.pth)\n")
            else:
                print(f"âš ï¸  New best found but checkpoint not yet saved: step {latest_event.step}")

        time.sleep(30)

    except KeyboardInterrupt:
        print("\nMonitor stopped")
        break
    except Exception as e:
        print(f"Error: {e}")
        time.sleep(30)
EOF

# ë°±ê·¸ë¼ìš´ë“œë¡œ best checkpoint ëª¨ë‹ˆí„° ì‹¤í–‰
nohup python3 /tmp/monitor_best_checkpoint.py > /tmp/best_ckpt_monitor.log 2>&1 &
MONITOR_PID=$!
echo "Best checkpoint monitor started (PID: ${MONITOR_PID})"
echo "ë¡œê·¸: /tmp/best_ckpt_monitor.log"
echo ""

echo "í•™ìŠµì„ ì‹œìž‘í•©ë‹ˆë‹¤..."
echo "TensorBoard: http://localhost:6006"
echo ""
echo "ì°¸ê³ : ë°ì´í„° ê²€ì¦ ìŠ¤í‚µ (SKIP_DATA_CHECK=1)"
echo "      ê²€ì¦í•˜ë ¤ë©´: SKIP_DATA_CHECK=0 ./tools/restart_from_base_with_best.sh"
echo ""

# ìž¬í•™ìŠµ ì‹œìž‘
SKIP_DATA_CHECK=1 \
LR=5e-6 \
WARMUP_STEPS=10000 \
MAX_STEPS=0 \
GRAD_CLIP=0.5 \
BATCH_SIZE=8 \
LOG_INTERVAL=100 \
VAL_INTERVAL=1000 \
EPOCHS=2 \
BASE_CHECKPOINT="${BASE_CHECKPOINT}" \
"${SCRIPT_DIR}/ko_step4_train_gpt.sh"

# í•™ìŠµ ì™„ë£Œ í›„ ëª¨ë‹ˆí„° ì¢…ë£Œ
kill ${MONITOR_PID} 2>/dev/null || true

echo ""
echo "================================================================"
echo "ìž¬í•™ìŠµ ì™„ë£Œ!"
echo "================================================================"
echo ""
echo "ì €ìž¥ëœ ì²´í¬í¬ì¸íŠ¸:"
echo "  - ìµœê³  ì„±ëŠ¥: /mnt/sda1/models/index-tts-ko/checkpoints/best_model.pth"
echo "  - ìµœì‹ : /mnt/sda1/models/index-tts-ko/checkpoints/latest.pth"
echo "  - ìµœê·¼ 5ê°œ: model_step*.pth"
echo ""
cat /mnt/sda1/models/index-tts-ko/checkpoints/best_loss.txt 2>/dev/null && \
  echo "Best mel_loss: $(cat /mnt/sda1/models/index-tts-ko/checkpoints/best_loss.txt)"
