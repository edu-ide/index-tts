#!/usr/bin/env python3
"""
ì¶”ê°€ mel ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ (target_audio â†’ mel)

melì´ ì—†ëŠ” ìƒ˜í”Œì— ëŒ€í•´ target_audioì—ì„œ mel-spectrogramì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
ê¸°ì¡´ mel íŒŒì¼ì€ ê±´ë„ˆë›°ê³  ìƒˆë¡œìš´ melë§Œ ìƒì„±í•©ë‹ˆë‹¤.

Usage:
    python tools/preprocess_target_mel.py \
        --manifest /mnt/sdb1/emilia-yodas/KO_preprocessed/gpt_pairs_train.jsonl \
        --data-dir /mnt/sdb1/emilia-yodas/KO_preprocessed \
        --num-workers 32 \
        --batch-size 50000

After preprocessing, run:
    bash tools/generate_mel_manifest_ssd.sh
"""

import argparse
import json
import os
import warnings
from pathlib import Path
from multiprocessing import Pool, cpu_count
from typing import Optional, Tuple
import numpy as np

# Suppress warnings
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", message=".*torchaudio.*")

import torch
import torchaudio
import torchaudio.transforms as T
from tqdm import tqdm


# s2mel config.yaml ê¸°ì¤€ mel ì„¤ì •
MEL_CONFIG = {
    "sample_rate": 22050,
    "n_fft": 1024,
    "win_length": 1024,
    "hop_length": 256,
    "n_mels": 80,
    "f_min": 0,
    "f_max": None,
}

# Global state for workers
_data_dir = None


def init_worker(data_dir: str):
    """Worker ì´ˆê¸°í™”"""
    global _data_dir
    _data_dir = Path(data_dir)
    warnings.filterwarnings("ignore")


def compute_mel_spectrogram(audio_path: str) -> Optional[np.ndarray]:
    """ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ mel-spectrogram ê³„ì‚°"""
    try:
        waveform, sr = torchaudio.load(audio_path)

        # monoë¡œ ë³€í™˜
        if waveform.shape[0] > 1:
            waveform = waveform.mean(dim=0, keepdim=True)

        # resample
        target_sr = MEL_CONFIG["sample_rate"]
        if sr != target_sr:
            resampler = T.Resample(orig_freq=sr, new_freq=target_sr)
            waveform = resampler(waveform)

        # mel-spectrogram
        mel_transform = T.MelSpectrogram(
            sample_rate=target_sr,
            n_fft=MEL_CONFIG["n_fft"],
            win_length=MEL_CONFIG["win_length"],
            hop_length=MEL_CONFIG["hop_length"],
            n_mels=MEL_CONFIG["n_mels"],
            f_min=MEL_CONFIG["f_min"],
            f_max=MEL_CONFIG["f_max"],
            power=2.0,
            normalized=False,
        )

        mel = mel_transform(waveform)  # [1, n_mels, time]
        mel = torch.log(torch.clamp(mel, min=1e-5))
        mel = mel.squeeze(0).transpose(0, 1).numpy()  # [time, n_mels]

        return mel.astype(np.float32)
    except Exception as e:
        return None


def process_sample(sample: dict) -> Tuple[str, str]:
    """ë‹¨ì¼ ìƒ˜í”Œ ì²˜ë¦¬ - target_audioì—ì„œ mel ì¶”ì¶œ"""
    global _data_dir

    target_id = sample.get("target_id")
    if not target_id:
        return target_id or "unknown", "no_target_id"

    # mel íŒŒì¼ ê²½ë¡œ
    mel_path = _data_dir / "mel" / f"{target_id}.npy"

    # ì´ë¯¸ ì¡´ì¬í•˜ë©´ skip
    if mel_path.exists():
        return target_id, "exists"

    # target_audio ê²½ë¡œ
    audio_rel_path = sample.get("target_audio_path")
    if not audio_rel_path:
        return target_id, "no_audio_path"

    audio_path = _data_dir / audio_rel_path
    if not audio_path.exists():
        return target_id, "audio_not_found"

    # mel ê³„ì‚°
    mel = compute_mel_spectrogram(str(audio_path))
    if mel is None:
        return target_id, "mel_failed"

    # ì €ì¥
    mel_path.parent.mkdir(parents=True, exist_ok=True)
    np.save(mel_path, mel)

    return target_id, "success"


def main():
    parser = argparse.ArgumentParser(description="ì¶”ê°€ mel ì „ì²˜ë¦¬ (target_audio â†’ mel)")
    parser.add_argument("--manifest", type=str, required=True,
                        help="ì…ë ¥ manifest (gpt_pairs_train.jsonl)")
    parser.add_argument("--data-dir", type=str, required=True,
                        help="ë°ì´í„° ë””ë ‰í† ë¦¬ (KO_preprocessed)")
    parser.add_argument("--num-workers", type=int, default=32,
                        help="ë³‘ë ¬ worker ìˆ˜")
    parser.add_argument("--batch-size", type=int, default=100000,
                        help="í•œ ë²ˆì— ì²˜ë¦¬í•  ìƒ˜í”Œ ìˆ˜ (ë©”ëª¨ë¦¬ ê´€ë¦¬)")
    parser.add_argument("--start-from", type=int, default=0,
                        help="ì‹œì‘ ë¼ì¸ ë²ˆí˜¸ (ì¬ì‹œì‘ìš©)")
    parser.add_argument("--limit", type=int, default=None,
                        help="ì²˜ë¦¬í•  ìµœëŒ€ ìƒ˜í”Œ ìˆ˜")
    args = parser.parse_args()

    data_dir = Path(args.data_dir)
    mel_dir = data_dir / "mel"
    mel_dir.mkdir(parents=True, exist_ok=True)

    # ê¸°ì¡´ mel íŒŒì¼ ìˆ˜ í™•ì¸
    existing_mel = len(list(mel_dir.glob("*.npy")))
    print(f"[Info] ê¸°ì¡´ mel íŒŒì¼: {existing_mel:,}ê°œ")

    # manifest ë¡œë“œ
    print(f"[Info] Manifest ë¡œë“œ: {args.manifest}")
    samples = []
    with open(args.manifest, "r", encoding="utf-8") as f:
        for i, line in enumerate(f):
            if i < args.start_from:
                continue
            if args.limit and len(samples) >= args.limit:
                break
            if line.strip():
                samples.append(json.loads(line))

    total = len(samples)
    print(f"[Info] ì²˜ë¦¬í•  ìƒ˜í”Œ: {total:,}ê°œ")
    print(f"[Info] Workers: {args.num_workers}")
    print(f"[Info] Batch size: {args.batch_size:,}")
    print(f"[Info] Mel config: sr={MEL_CONFIG['sample_rate']}, n_mels={MEL_CONFIG['n_mels']}")
    print()

    # í†µê³„
    stats = {"success": 0, "exists": 0, "no_audio_path": 0, "audio_not_found": 0, "mel_failed": 0}

    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
    for batch_start in range(0, total, args.batch_size):
        batch_end = min(batch_start + args.batch_size, total)
        batch = samples[batch_start:batch_end]

        print(f"\n[Batch] {batch_start:,} ~ {batch_end:,} ({len(batch):,}ê°œ)")

        with Pool(
            processes=args.num_workers,
            initializer=init_worker,
            initargs=(str(data_dir),)
        ) as pool:
            with tqdm(total=len(batch), desc="Processing", unit="samples",
                      dynamic_ncols=True, smoothing=0.05) as pbar:

                chunksize = max(1, len(batch) // (args.num_workers * 100))
                chunksize = min(chunksize, 1000)

                for target_id, status in pool.imap_unordered(process_sample, batch, chunksize=chunksize):
                    if status in stats:
                        stats[status] += 1

                    pbar.set_postfix({
                        "new": stats["success"],
                        "skip": stats["exists"],
                        "err": stats["audio_not_found"] + stats["mel_failed"]
                    })
                    pbar.update(1)

    # ê²°ê³¼ ì¶œë ¥
    print()
    print("=" * 60)
    print("ğŸ“Š Results:")
    print(f"   âœ… ìƒˆë¡œ ìƒì„±: {stats['success']:,}")
    print(f"   â­ï¸  ì´ë¯¸ ì¡´ì¬: {stats['exists']:,}")
    print(f"   âŒ ì˜¤ë””ì˜¤ ì—†ìŒ: {stats['audio_not_found']:,}")
    print(f"   âŒ mel ì‹¤íŒ¨: {stats['mel_failed']:,}")
    print("=" * 60)

    # ìµœì¢… mel íŒŒì¼ ìˆ˜
    final_mel = len(list(mel_dir.glob("*.npy")))
    print(f"\n[Info] ìµœì¢… mel íŒŒì¼: {final_mel:,}ê°œ (+{final_mel - existing_mel:,})")

    print()
    print("âœ… Complete!")
    print()
    print("ë‹¤ìŒ ë‹¨ê³„:")
    print("  1. manifest ì¬ìƒì„±:")
    print("     bash tools/generate_mel_manifest_ssd.sh")
    print()
    print("  2. í•™ìŠµ ì¬ì‹œì‘:")
    print("     bash tools/run_stage2_training.sh")


if __name__ == "__main__":
    main()
