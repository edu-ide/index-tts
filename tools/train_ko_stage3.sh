#!/usr/bin/env bash
# IndexTTS2 Stage 3: Fine-tuning with Frozen Feature Conditioners
#
# Stage 3 ì„¤ì • (IndexTTS2 ë…¼ë¬¸ ê¸°ë°˜):
# - Speaker perceiver conditioner: FROZEN (Stage 1ì—ì„œ í•™ìŠµë¨)
# - Emotion perceiver conditioner: FROZEN (Stage 2ì—ì„œ í•™ìŠµë¨)
# - GPT backbone: TRAINABLE
# - GRL: DISABLED (Stage 2ì—ì„œë§Œ ì‚¬ìš©)
# - Learning Rate: 1e-4 (Stage 1/2ë³´ë‹¤ ë‚®ìŒ)
# - ì „ì²´ ë°ì´í„°ì…‹ ì‚¬ìš©
#
# ëª©ì :
#   - Stage 1, 2ì—ì„œ í•™ìŠµëœ featureë¥¼ ê³ ì •
#   - GPTì˜ ìƒì„± í’ˆì§ˆë§Œ ê°œì„ 
#   - Overfitting ë°©ì§€
#
# ì°¸ê³ ë¬¸í—Œ:
# - IndexTTS2 (arXiv:2506.21619v2)

set -euo pipefail

echo "================================================================"
echo "ğŸ¯ IndexTTS2 Stage 3: Fine-tuning (Frozen Conditioners)"
echo "================================================================"
echo ""

# í™˜ê²½ í™•ì¸
if [[ -z "${VIRTUAL_ENV:-}" ]]; then
  echo "[ERROR] ê°€ìƒí™˜ê²½ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤." >&2
  echo "ì‹¤í–‰: source /mnt/sdc1/ws/workspace/.venv_indextts/bin/activate" >&2
  exit 1
fi

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "${SCRIPT_DIR}")"

# ============================================================
# Stage 3 Configuration
# ============================================================

# Paths
DATASET_DIR="${DATASET_DIR:-/mnt/sda1/emilia-yodas/KO_preprocessed}"
CHECKPOINT_DIR="${CHECKPOINT_DIR:-/mnt/sda1/models/index-tts-ko/stage3}"
STAGE2_CHECKPOINT="${STAGE2_CHECKPOINT:-/mnt/sda1/models/index-tts-ko/stage2/checkpoints/best_model.pth}"

# Model config
CONFIG="${CONFIG:-/mnt/sda1/models/IndexTTS-2/config.yaml}"
TOKENIZER="${TOKENIZER:-/mnt/sda1/models/IndexTTS-2/tokenizer.model}"

# Training hyperparameters (Stage 3 specific)
BATCH_SIZE="${BATCH_SIZE:-8}"
GRAD_ACC="${GRAD_ACC:-8}"
LR="${LR:-1e-4}"  # Lower than Stage 1/2
WARMUP_STEPS="${WARMUP_STEPS:-2000}"
EPOCHS="${EPOCHS:-1}"
GRAD_CLIP="${GRAD_CLIP:-0.5}"

# Logging
LOG_INTERVAL="${LOG_INTERVAL:-100}"
VAL_INTERVAL="${VAL_INTERVAL:-1000}"

# ============================================================
# Validation
# ============================================================

echo "ğŸ“‚ Paths:"
echo "  - Dataset: ${DATASET_DIR}"
echo "  - Output: ${CHECKPOINT_DIR}"
echo "  - Stage 2 checkpoint: ${STAGE2_CHECKPOINT}"
echo ""

# Check Stage 2 checkpoint
if [[ ! -f "${STAGE2_CHECKPOINT}" ]]; then
  echo "[ERROR] Stage 2 checkpoint not found: ${STAGE2_CHECKPOINT}" >&2
  echo "" >&2
  echo "Stage 3ëŠ” Stage 2 ì™„ë£Œ í›„ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤:" >&2
  echo "  1. Stage 2 í•™ìŠµ ë¨¼ì € ì‹¤í–‰:" >&2
  echo "     ./tools/train_ko_stage2.sh" >&2
  echo "  2. Stage 2 checkpoint í™•ì¸:" >&2
  echo "     ls -lh /mnt/sda1/models/index-tts-ko/stage2/checkpoints/best_model.pth" >&2
  echo "  3. Stage 3 í•™ìŠµ ì‹¤í–‰:" >&2
  echo "     ./tools/train_ko_stage3.sh" >&2
  echo "" >&2
  exit 1
fi

# GPU í™•ì¸
GPU_MEM=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
GPU_NAME=$(nvidia-smi --query-gpu=name --format=csv,noheader | head -1)

echo "âœ… GPU: ${GPU_NAME}"
echo "âœ… VRAM: ${GPU_MEM}MB"
echo ""

# ============================================================
# Stage 3 Configuration Summary
# ============================================================

echo "ğŸ“Š Stage 3 í•˜ì´í¼íŒŒë¼ë¯¸í„°:"
echo "  - Batch Size: ${BATCH_SIZE}"
echo "  - Gradient Accumulation: ${GRAD_ACC} (ì‹¤íš¨ batch ${((BATCH_SIZE * GRAD_ACC))})"
echo "  - Learning Rate: ${LR} (Stage 1/2ë³´ë‹¤ ë‚®ìŒ)"
echo "  - Warmup Steps: ${WARMUP_STEPS}"
echo "  - Epochs: ${EPOCHS}"
echo "  - Gradient Clip: ${GRAD_CLIP}"
echo ""
echo "ğŸ”’ Freezing:"
echo "  - Speaker Perceiver: FROZEN (Stage 1ì—ì„œ í•™ìŠµì™„ë£Œ)"
echo "  - Emotion Perceiver: FROZEN (Stage 2ì—ì„œ í•™ìŠµì™„ë£Œ)"
echo "  - GPT Backbone: TRAINABLE"
echo "  - GRL: DISABLED (Stage 2ì—ì„œë§Œ ì‚¬ìš©)"
echo ""
echo "ğŸ“š ì°¸ê³ :"
echo "  - Stage 3ëŠ” feature conditionerë¥¼ ê³ ì •í•˜ê³  GPTë§Œ fine-tuningí•©ë‹ˆë‹¤"
echo "  - Stage 1, 2ì—ì„œ í•™ìŠµëœ speaker/emotion featureë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤"
echo "  - Overfittingì„ ë°©ì§€í•˜ê³  ìƒì„± í’ˆì§ˆë§Œ ê°œì„ í•©ë‹ˆë‹¤"
echo ""
echo "================================================================"
echo ""

# ì‚¬ìš©ì í™•ì¸
read -p "Stage 3 í•™ìŠµì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
  echo "ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤."
  exit 0
fi

echo ""
echo "ğŸ¬ Stage 3 í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤..."
echo "ğŸ“Š TensorBoard: http://localhost:6006"
echo "ğŸ“ ì²´í¬í¬ì¸íŠ¸: ${CHECKPOINT_DIR}/"
echo ""

# ============================================================
# Stage 3 Training
# ============================================================

echo ""
echo "================================================================"
echo "âœ… Stage 3 í•™ìŠµ ì‹œì‘ (Frozen Conditioners Fine-tuning)"
echo "================================================================"
echo ""
echo "ğŸ“Š ì£¼ìš” ì„¤ì •:"
echo "  âœ… Feature conditioners frozen"
echo "  âœ… GPT backbone trainable"
echo "  âœ… GRL disabled"
echo "  âœ… Lower learning rate for fine-tuning"
echo ""
echo "================================================================"
echo ""

# Stage 3 Training with Frozen Conditioners
python trainers/train_gpt_v2.py \
    --train-manifest ${DATASET_DIR}/train_manifest.jsonl \
    --val-manifest ${DATASET_DIR}/val_manifest.jsonl \
    --tokenizer ${TOKENIZER} \
    --config ${CONFIG} \
    --base-checkpoint ${STAGE2_CHECKPOINT} \
    --output-dir ${CHECKPOINT_DIR} \
    --batch-size ${BATCH_SIZE} \
    --grad-accumulation ${GRAD_ACC} \
    --learning-rate ${LR} \
    --warmup-steps ${WARMUP_STEPS} \
    --epochs ${EPOCHS} \
    --grad-clip ${GRAD_CLIP} \
    --freeze-conditioners \
    --log-interval ${LOG_INTERVAL} \
    --val-interval ${VAL_INTERVAL}

echo ""
echo "================================================================"
echo "âœ… Stage 3 í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"
echo "================================================================"
