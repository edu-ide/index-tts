#!/usr/bin/env bash
# μµμ ν™”λ ν•κµ­μ–΄ GPT ν•™μµ μ¤ν¬λ¦½νΈ - RTX 4090 24GB (Fine-tuning)
# Phase 1: λΉ λ¥Έ μλ ΄ (Step 0 β†’ 240k)
#
# κ³Όν•™μ  κ·Όκ±° (μ΄μ „ ν•™μµ λ°μ΄ν„° λ¶„μ„ κΈ°λ°):
# - LR: 2e-5 (κ³µκ²©μ , λΉ λ¥Έ μλ ΄)
# - Batch: 8 (RTX 4090 24GB κ²€μ¦λ μ•μ „κ°’)
# - Grad Accumulation: 1 (λΉ λ¥Έ ν•™μµ, batch 8)
# - Warmup: 1,000 steps
# - Grad Clip: 1.0 (LRμ— λ§μ¶ μ•μ „μ¥μΉ, μ΄μ „ λ€λΉ„ μλ ΄ μ†λ„ ν–¥μƒ)
#
# μ΄μ „ ν•™μµ κ²°κ³Ό (GRAD_ACC=1, LR=2e-5):
#   - Step 247800: Loss=0.9648 (μµμ €μ  λ‹¬μ„±!)
#   - Step 250k μ΄ν›„: Overfitting μ‹μ‘
#
# Phase 1 λ©ν‘: Step 240kμ—μ„ Loss < 1.0 λ‹¬μ„±
# Phase 2 μ „ν™: Step 240kμ—μ„ GRAD_ACC=8, LR=5e-6μΌλ΅ μ•μ •ν™”
#
# μμƒ ν•™μµ μ‹κ°„: ~20μ‹κ°„ (240k steps, GRAD_ACC=1λ΅ λΉ λ¦„)
#
# μ£Όμ: Cross-lingual fine-tuning (English base β†’ Korean)
#       Phase 1: λΉ λ¥Έ μλ ΄ (ν„μ¬)
#       Phase 2: μ•μ •ν™” λ° μΌλ°ν™” (Step 240k μ΄ν›„)

set -euo pipefail

echo "================================================================"
echo "π€ ν•κµ­μ–΄ GPT Fine-tuning - RTX 4090 24GB"
echo "π“ Phase 1: λΉ λ¥Έ μλ ΄ (Step 0 β†’ 240k)"
echo "================================================================"
echo ""
echo "π“ Phase 1 ν•μ΄νΌνλΌλ―Έν„°:"
echo "  - GPU: RTX 4090 24GB"
echo "  - Batch Size: 8"
echo "  - Gradient Accumulation: 1 (λΉ λ¥Έ ν•™μµ)"
echo "  - Learning Rate: 2e-5 (κ³µκ²©μ )"
echo "  - Warmup Steps: 1,000"
echo "  - Max Steps: 240,000"
echo "  - Gradient Clip: 1.0 (LRμ— λ§μ¶ μ•μ „μ¥μΉ)"
echo ""
echo "π’΅ 2λ‹¨κ³„ ν•™μµ μ „λµ:"
echo "  - Phase 1 (0β†’240k): GRAD_ACC=1, LR=2e-5 (λΉ λ¥Έ μλ ΄)"
echo "  - Phase 2 (240kβ†’λ): GRAD_ACC=8, LR=5e-6 (μ•μ •ν™”)"
echo "  - μ΄μ „ κ²°κ³Ό: Step 247kμ—μ„ Loss=0.96 λ‹¬μ„±"
echo "  - λ©ν‘: Overfitting λ°©μ§€ν•λ©° μµμ €μ  λ„λ‹¬"
echo ""
echo "π― λ©ν‘:"
echo "  - text_loss < 0.9"
echo "  - mel_loss < 3.5"
echo "  - ν•™μµ μ‹κ°„: ~45μ‹κ°„ (3 epochs)"
echo ""
echo "π“ μ°Έκ³ λ¬Έν—:"
echo "  - IndexTTS2 (arXiv:2506.21619v2) - Base architecture"
echo "  - 2024-2025 Fine-tuning research - LR scheduling"
echo "  - Warmup-Stable-Decay (2024) - Modern LR schedule"
echo ""
echo "β οΈ  μ£Όμμ‚¬ν•­:"
echo "  - Cross-lingual fine-tuning (not from scratch)"
echo "  - Phase 1: Baseline ν™•λ³΄"
echo "  - Phase 2: GRL emotion disentanglement μμ •"
echo ""
echo "================================================================"

# ν™κ²½ ν™•μΈ
if [[ -z "${VIRTUAL_ENV:-}" ]]; then
  echo "[ERROR] κ°€μƒν™κ²½μ΄ ν™μ„±ν™”λμ§€ μ•μ•μµλ‹λ‹¤." >&2
  echo "μ‹¤ν–‰: source /mnt/sdc1/ws/workspace/.venv_indextts/bin/activate" >&2
  exit 1
fi

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# GPU ν™•μΈ
GPU_MEM=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
GPU_NAME=$(nvidia-smi --query-gpu=name --format=csv,noheader | head -1)

echo "β… GPU: ${GPU_NAME}"
echo "β… VRAM: ${GPU_MEM}MB"
echo ""

if [[ ${GPU_MEM} -gt 40000 ]]; then
  echo "[INFO] 48GB+ GPU κ°μ§€λμ—μµλ‹λ‹¤." >&2
  echo "      λ” λΉ λ¥Έ ν•™μµμ„ μ„ν•΄ train_ko_optimized_a6000.sh μ‚¬μ© κ¶μ¥" >&2
  echo "" >&2
fi

# μ‚¬μ©μ ν™•μΈ μ¤ν‚µ (μλ™ μ‹¤ν–‰)
echo "μλ™μΌλ΅ ν•™μµμ„ μ‹μ‘ν•©λ‹λ‹¤..."

echo ""
echo "π¬ Phase 1 ν•™μµμ„ μ‹μ‘ν•©λ‹λ‹¤..."
echo "π“ TensorBoard: http://localhost:6006"
echo "π“ μ²΄ν¬ν¬μΈνΈ: /mnt/sda1/models/index-tts-ko/checkpoints/"
echo ""
echo "β΅ Phase 1 μ „λµ:"
echo "   - GRAD_ACC=1λ΅ λΉ λ¥Έ ν•™μµ"
echo "   - Step 240kμ—μ„ μλ™ μΆ…λ£"
echo "   - μ΄ν›„ Phase 2λ΅ μλ™ μ „ν™ ν•„μ”"
echo "   - Phase 2: GRAD_ACC=8, LR=5e-6"
echo ""

# Phase 1: λΉ λ¥Έ μλ ΄ (Step 0 β†’ 240k)
# μ΄μ „ ν•™μµ λ°μ΄ν„° κΈ°λ° μ „λµ:
#   - GRAD_ACC=1λ΅ λΉ λ¥΄κ² μλ ΄
#   - Step 247kμ—μ„ Loss=0.96 λ‹¬μ„±
#   - Step 240kμ—μ„ λ©μ¶”κ³  Phase 2λ΅ μ „ν™ μμ •
SKIP_DATA_CHECK=1 \
LR=2e-5 \
WARMUP_STEPS=1000 \
BATCH_SIZE=8 \
GRAD_ACC=1 \
GRAD_CLIP=1.0 \
LOG_INTERVAL=100 \
VAL_INTERVAL=10000 \
MAX_STEPS=240000 \
EPOCHS=999 \
BASE_CHECKPOINT="/mnt/sda1/models/IndexTTS-2/gpt.pth" \
"${SCRIPT_DIR}/ko_step4_train_gpt.sh"

echo ""
echo "================================================================"
echo "β… Phase 1 ν•™μµ μ™„λ£!"
echo "================================================================"
echo ""
echo "π“ μ €μ¥λ μ²΄ν¬ν¬μΈνΈ:"
echo "  - μµκ³  μ„±λ¥: /mnt/sda1/models/index-tts-ko/checkpoints/best_model.pth"
echo "  - μµμ‹ : /mnt/sda1/models/index-tts-ko/checkpoints/latest.pth"
echo ""
if [[ -f "/mnt/sda1/models/index-tts-ko/checkpoints/best_loss.txt" ]]; then
  echo "π― Best text_loss: $(cat /mnt/sda1/models/index-tts-ko/checkpoints/best_loss.txt)"
fi
echo ""
echo "λ‹¤μ λ‹¨κ³„:"
echo "  1. TensorBoardλ΅ ν•™μµ κ³΅μ„  ν™•μΈ"
echo "  2. Phase 2 μ‹μ‘: tools/train_ko_optimized_4090_phase2.sh"
echo "  3. best_model.pthλ΅ μμ„± μƒμ„± ν…μ¤νΈ"
echo ""
