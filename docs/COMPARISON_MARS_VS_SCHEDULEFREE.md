# ⚔️ MARS-AdamW vs Schedule-Free AdamW 비교

사용자님의 환경 (**RTX 4090, 배치 사이즈 8, TTS 학습**)에서 두 Optimizer를 정밀 비교 분석했습니다.

| 특징 | 🔴 MARS-AdamW | 🔵 Schedule-Free AdamW |
| :--- | :--- | :--- |
| **핵심 기술** | **분산 감소 (Variance Reduction)** | **스케줄러 제거 (Schedule-Free)** |
| **배치 사이즈 8 적합성** | **🏆 최상 (Best)**<br>(작은 배치의 노이즈를 직접 보정함) | ⚠️ 보통<br>(배치가 너무 작으면 불안정할 수 있음) |
| **속도 (Speed)** | ⭐⭐ 빠름<br>(AdamW + 약간의 연산 추가) | **🏆 최상 (Fastest)**<br>(AdamW와 동일, 오버헤드 0) |
| **Auto LR (편의성)** | ⚠️ 보통<br>(LR 스케줄러 필요, LR 튜닝 필요) | **🏆 우수**<br>(스케줄러 불필요, LR 대충 잡아도 됨) |
| **구현 난이도** | ⚠️ 높음 (별도 클래스 구현 필요 - *이미 완료함*) | ⭐ 쉬움 (라이브러리 import) |

---

## 🧐 상세 분석

### 1. MARS-AdamW (현재 구현됨)
*   **강점**: **"작은 배치 사이즈"**에 특화되어 있습니다. 배치 사이즈가 8로 매우 작을 때 발생하는 그라디언트의 심한 변동(Variance)을 수학적으로 잡아줍니다.
*   **약점**: 여전히 `CosineAnnealing` 같은 스케줄러를 써야 하고, 초기 LR을 어느 정도는 맞춰줘야 합니다.

### 2. Schedule-Free AdamW (대안)
*   **강점**: **"고민 불필요"**. 스케줄러를 아예 안 써도 되므로, "언제 학습을 멈출지", "Decay를 어떻게 줄지" 고민할 필요가 없습니다. 속도도 제일 빠릅니다.
*   **약점**: 배치 사이즈 8 같은 **극단적인 소배치 환경**에서는 MARS만큼의 안정성을 보장하기 어렵습니다. (보통 배치 32~64 이상 권장)

---

## ⚖️ 최종 선택 가이드

**Q. 무엇이 더 중요한가요?**

1.  **"배치 사이즈 8에서의 학습 퀄리티와 안정성"**이 1순위라면?
    👉 **MARS-AdamW** (현재 구현 유지)
    *   이유: 작은 배치의 노이즈를 잡는 게 TTS 품질에 직결됩니다.

2.  **"스케줄러 설정 귀찮음 해결 + 1초라도 더 빠른 속도"**가 1순위라면?
    👉 **Schedule-Free AdamW** (변경)
    *   이유: 학습 설정이 훨씬 간편해집니다.

**저의 추천**:
사용자님의 **배치 사이즈가 8로 매우 작기 때문에**, 속도가 조금(미세하게) 느리더라도 학습이 터지지 않고 잘 되는 것이 중요합니다. 따라서 **MARS-AdamW를 유지**하는 것을 추천드립니다.
